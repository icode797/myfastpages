{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding AI\n",
    "\n",
    "Hi there! Today I'll show you how AI works! No coding or math knowledge is required! I have lerned this from the [fast.ai](https:fast.ai) course Deep Learning for coders lessons one and two, I encourage you to try them to if you know how to code or will learn how to code.\n",
    "\n",
    "## A (very) brief history and introduction\n",
    "The most common AI is machine learning, or a neural network. It's modeled after a real neuron, like this:\n",
    "<img width=300 src=\"images/neuron.png\" alt=\"Mark 1 perceptron\"></img>\n",
    "> Credit: https://www.quora.com/What-is-the-differences-between-artificial-neural-network-computer-science-and-biological-neural-network\n",
    "\n",
    "\n",
    "\n",
    "In 1943 Warren McCulloch, a neurophysiologist, and Walter Pitts, a logician, developed the model of the artificial neuron. The Mark 1 perceptron was the first device to use the artificial neuron, and it was not made by McCulloch or Pitts but by Frank Rosenblatt, who build on the work of McCulloch and Pitts and gave the artificial neuron the ability to learn. Here is Rosenblatt's device, the Mark 1 Perceptron:\n",
    "\n",
    "<img width=200 src=\"https://i.redd.it/bo3xoa8y4m341.jpg\" alt=\"Mark 1 perceptron\"></img>\n",
    "> Credit: https://i.redd.it/bo3xoa8y4m341.jpg\n",
    "\n",
    "So, if AI started in over 70 years ago, should it be more advanced today? Probably, but a book called *Perceptrons* detailed the perceptron, and showed that the device couldn't solve basic but critical math problems. The book also showed that multiple layers of these devices could solve the problems. In fact, the *universal approximation theorum* shows that a neural network with multiple layers can solve any problem with any accuracy, in theory. However, instead of building with multiple layers, scientists largely ignored neural networks for decades.\n",
    "\n",
    "Eventually, in the 1980's, neural networks were built with two layers, and were used to solve real, practical problems. But although two layers were theoretically enough, in reality more layers were needed to make the best models. Neural networks have only been being built with many layers in the past decade. I'll show you what I mean by layers soon, but first..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Model!\n",
    "\n",
    "Often, it's better to learn from the top-down - doing something first, and *then* explaining it. I encourage you to make a model now with https://teachablemachine.withgoogle.com or a similar software. Simply click on \"Get Started\" and then on image project and follow the directions. Then, I'll explain how it works.\n",
    "\n",
    "> Note: Teachable Machine requires no software download or sign-up!\n",
    "\n",
    "> Note: If you are following the fast.ai course for coders, there is a simple model in the \"intro\" notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So how does it work?\n",
    "\n",
    "Let's go back to the artificial neuron before:\n",
    "<img width=300 src=\"images/neuron.png\" alt=\"Artificial Neuron Model\"></img>\n",
    "> Credit: https://www.quora.com/What-is-the-differences-between-artificial-neural-network-computer-science-and-biological-neural-network\n",
    "\n",
    "It has input and output. Actually, it has multiple inputs, and multiple possible outputs, and a function in the middle. But this simpler diagram might make more sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"432pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 431.68 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-94 427.68,-94 427.68,4 -4,4\"/>\n",
       "<!-- architecture -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>architecture</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"270.69,-70 168.69,-70 164.69,-66 164.69,-20 266.69,-20 270.69,-24 270.69,-70\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"266.69,-66 164.69,-66 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"266.69,-66 266.69,-20 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"266.69,-66 270.69,-70 \"/>\n",
       "<text text-anchor=\"middle\" x=\"217.69\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">architecture</text>\n",
       "</g>\n",
       "<!-- prediction -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>prediction</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"365.18\" cy=\"-45\" rx=\"58.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"365.18\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">prediction</text>\n",
       "</g>\n",
       "<!-- architecture&#45;&gt;prediction -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>architecture&#45;&gt;prediction</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M270.8,-45C279.13,-45 287.84,-45 296.46,-45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"296.51,-48.5 306.51,-45 296.51,-41.5 296.51,-48.5\"/>\n",
       "</g>\n",
       "<!-- inputs -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>inputs</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"64.34\" cy=\"-72\" rx=\"40.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"64.34\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">inputs</text>\n",
       "</g>\n",
       "<!-- inputs&#45;&gt;architecture -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>inputs&#45;&gt;architecture</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M101.98,-65.46C117.7,-62.66 136.52,-59.3 154.33,-56.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"155.43,-59.48 164.66,-54.28 154.2,-52.59 155.43,-59.48\"/>\n",
       "</g>\n",
       "<!-- parameters -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>parameters</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"64.34\" cy=\"-18\" rx=\"64.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"64.34\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">parameters</text>\n",
       "</g>\n",
       "<!-- parameters&#45;&gt;architecture -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>parameters&#45;&gt;architecture</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M119.13,-27.6C130.56,-29.64 142.73,-31.81 154.45,-33.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"154.14,-37.4 164.6,-35.71 155.37,-30.51 154.14,-37.4\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f1d60eca550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "gv('''architecture[shape=box3d width=1 height=0.7]\n",
    "inputs->architecture->prediction; parameters->architecture''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inputs** and **Parameters** go into the **architecture**, which generates a **prediction**. \n",
    "For a quick comparison, here is a normal computer program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"382pt\" height=\"112pt\"\n",
       " viewBox=\"0.00 0.00 381.57 112.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 108)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-108 377.57,-108 377.57,4 -4,4\"/>\n",
       "<!-- program -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>program</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"79.3,-50 5.3,-50 1.3,-46 1.3,0 75.3,0 79.3,-4 79.3,-50\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"75.3,-46 1.3,-46 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"75.3,-46 75.3,0 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"75.3,-46 79.3,-50 \"/>\n",
       "<text text-anchor=\"middle\" x=\"40.3\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\">program</text>\n",
       "</g>\n",
       "<!-- inputs -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>inputs</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"40.3\" cy=\"-86\" rx=\"40.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"40.3\" y=\"-82.3\" font-family=\"Times,serif\" font-size=\"14.00\">inputs</text>\n",
       "</g>\n",
       "<!-- architecture -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>architecture</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"185.49\" cy=\"-86\" rx=\"68.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"185.49\" y=\"-82.3\" font-family=\"Times,serif\" font-size=\"14.00\">architecture</text>\n",
       "</g>\n",
       "<!-- inputs&#45;&gt;architecture -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>inputs&#45;&gt;architecture</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M80.8,-86C88.86,-86 97.61,-86 106.48,-86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.53,-89.5 116.53,-86 106.53,-82.5 106.53,-89.5\"/>\n",
       "</g>\n",
       "<!-- output -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>output</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"331.98\" cy=\"-86\" rx=\"41.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"331.98\" y=\"-82.3\" font-family=\"Times,serif\" font-size=\"14.00\">output</text>\n",
       "</g>\n",
       "<!-- architecture&#45;&gt;output -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>architecture&#45;&gt;output</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M254.5,-86C263.04,-86 271.67,-86 279.89,-86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"280.05,-89.5 290.05,-86 280.05,-82.5 280.05,-89.5\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f1d60eca5e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "gv('''program[shape=box3d width=1 height=0.7]\n",
    "inputs->architecture->output''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the difference? The neural networks have parameters, not just inputs. It might seem like a small change, but it is very powerful. Think of the parameters as what it has learned from running the program last time - it gets a bit smarter each time and saves that knowledge for when it runs the next time. \n",
    "\n",
    "Maybe you think that a \"real\" neural network can't be this simple. The full diagram is a bit more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"587pt\" height=\"139pt\"\n",
       " viewBox=\"0.00 0.00 587.27 139.44\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 135.44)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-135.44 583.27,-135.44 583.27,4 -4,4\"/>\n",
       "<!-- model -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>model</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"271.69,-84.44 169.69,-84.44 165.69,-80.44 165.69,-34.44 267.69,-34.44 271.69,-38.44 271.69,-84.44\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"267.69,-80.44 165.69,-80.44 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"267.69,-80.44 267.69,-34.44 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"267.69,-80.44 271.69,-84.44 \"/>\n",
       "<text text-anchor=\"middle\" x=\"218.69\" y=\"-55.74\" font-family=\"Times,serif\" font-size=\"14.00\">architecture</text>\n",
       "</g>\n",
       "<!-- predictions -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>predictions</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"421.38\" cy=\"-59.44\" rx=\"63.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"421.38\" y=\"-55.74\" font-family=\"Times,serif\" font-size=\"14.00\">predictions</text>\n",
       "</g>\n",
       "<!-- model&#45;&gt;predictions -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>model&#45;&gt;predictions</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271.89,-59.44C294.86,-59.44 322.24,-59.44 347.19,-59.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"347.35,-62.94 357.35,-59.44 347.35,-55.94 347.35,-62.94\"/>\n",
       "</g>\n",
       "<!-- inputs -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>inputs</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"64.34\" cy=\"-79.44\" rx=\"40.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"64.34\" y=\"-75.74\" font-family=\"Times,serif\" font-size=\"14.00\">inputs</text>\n",
       "</g>\n",
       "<!-- inputs&#45;&gt;model -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>inputs&#45;&gt;model</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.39,-74.45C119.09,-72.39 137.69,-69.94 155.28,-67.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.02,-71.07 165.48,-66.29 155.11,-64.13 156.02,-71.07\"/>\n",
       "</g>\n",
       "<!-- loss -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>loss</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"550.67\" cy=\"-88.44\" rx=\"28.7\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"550.67\" y=\"-84.74\" font-family=\"Times,serif\" font-size=\"14.00\">loss</text>\n",
       "</g>\n",
       "<!-- predictions&#45;&gt;loss -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>predictions&#45;&gt;loss</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M471.6,-70.65C485.51,-73.82 500.39,-77.21 513.39,-80.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"512.83,-83.64 523.36,-82.45 514.39,-76.81 512.83,-83.64\"/>\n",
       "</g>\n",
       "<!-- parameters -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>parameters</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"64.34\" cy=\"-25.44\" rx=\"64.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"64.34\" y=\"-21.74\" font-family=\"Times,serif\" font-size=\"14.00\">parameters</text>\n",
       "</g>\n",
       "<!-- parameters&#45;&gt;model -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>parameters&#45;&gt;model</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M115.23,-36.57C128.09,-39.44 142.09,-42.57 155.5,-45.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"155.08,-49.05 165.6,-47.82 156.6,-42.22 155.08,-49.05\"/>\n",
       "</g>\n",
       "<!-- labels -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>labels</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"421.38\" cy=\"-113.44\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"421.38\" y=\"-109.74\" font-family=\"Times,serif\" font-size=\"14.00\">labels</text>\n",
       "</g>\n",
       "<!-- labels&#45;&gt;loss -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>labels&#45;&gt;loss</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M457.17,-106.61C474.52,-103.2 495.5,-99.08 513.1,-95.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"513.87,-99.04 523.01,-93.68 512.52,-92.17 513.87,-99.04\"/>\n",
       "</g>\n",
       "<!-- loss&#45;&gt;parameters -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>loss&#45;&gt;parameters</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M536.99,-72.56C525.16,-59.11 506.22,-40.73 485.08,-32.44 365.43,14.45 211.47,0.07 127.23,-13.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.61,-9.98 117.31,-15.07 127.75,-16.89 126.61,-9.98\"/>\n",
       "<text text-anchor=\"middle\" x=\"314.69\" y=\"-6.24\" font-family=\"Times,serif\" font-size=\"14.00\">update</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f1d60eca940>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "#caption Detailed training loop\n",
    "#id detailed_loop\n",
    "gv('''ordering=in\n",
    "model[shape=box3d width=1 height=0.7 label=architecture]\n",
    "inputs->model->predictions; parameters->model; labels->loss; predictions->loss\n",
    "loss->parameters[constraint=false label=update]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The additional parts of the diagram are **labels**, **loss**, and **update**. These parts show how the model gets smarter each time, or how it gets it's parameters. The **labels** are the answer key. They tell the model if it is right or wrong. If I am training a model to catagorize cats and dogs, the inputs would be images and the labels would be either \"cat\" or \"dog.\" The **loss** is calculated by a function. In my cat and dog images, the loss would tell the computer not just that it was right or wrong, but how right or how wrong so it can have more accurate updates. The **update** updates the **parameters** depending on how right or wrong its **prediction** was. **When the update happens, it has now learned.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I won't go into detail about what the parameters actually are - I don't completely know - but just know that they are values that are adjusted until the neural network gets as accurate as it can. So, the longer we train it, the better it gets, right?\n",
    "Yes and No. Say I have 100 cat photos and 100 dog photos, and I train my neural network with them many, many times. Yes, it will get better at those 100 cat photos and 100 dog photos, but it will get too used to them and will have a harder time on images it has never seen before. It will still work, but it will be more confused when it sees new images. This is called **overfitting**. Here is a picture that might help you understand:\n",
    "<img width=500 src=\"https://miro.medium.com/max/1125/1*_7OPgojau8hkiPUiHoGK_w.png\" alt=\"Mark 1 perceptron\"></img>\n",
    "> Credit: https://miro.medium.com/max/1125/1*_7OPgojau8hkiPUiHoGK_w.png\n",
    "\n",
    "The image shows that when it overfits, it doesn't have a generalized line but instead has a line that has fitted to the exact data it was trained on. Make sure it doesn't overfit, some data in any dataset must be reserved for validation set. The validation set must stay seperate and is not used for training the model. \n",
    "\n",
    "Congratulations! You now know a lot more about machine learning than most people. But we still haven't gotten to talk about layers, which, as I mentioned earlier, were key to using machine learning for more challenging problems. Read the second section to learn more, still without any code or math.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digging Deeper\n",
    "\n",
    "In this section, we'll talk about deep learning and layers. Actually, deep learning just means that there are multiple layers. And, as I said earlier, a lack of layers held back the field of AI for many decades. But what exactly are layers? I'm going to show you the layers of an image network similar to the one you trained with teachable machine:\n",
    "\n",
    "<img width=900 src=\"cnn.png\" alt=\"CNN Layers\"></img>\n",
    "> Credit: KindPNG\n",
    "\n",
    "See how it starts in layer 1 recognizing super-simple patterns, then starts to recognize more detailed parts of images. In layer 5 it is a recognizable picture, although not the full picture. There are still a few more layers not shown in the image, they are the top layers. \n",
    "\n",
    "When you trained your Teachable Machine model, you weren't actually training it from scratch. You were training from a pre-trained model like the one in the picture, and then updating those top layers not seen in the image so that they did what you want them to do. You can see that the first layers of the model are identifying common patterns. Instead of making the model learn common patterns all over when we use Teachable Machine, it uses pre-trained early layers. This is called **transfer learning**. Transfer learning is very useful and requires less data.\n",
    "\n",
    "There is a huge database called ImageNet, and powerful neural networks trained off of ImageNet are great for transfer learning. This is so powerful that researchers will convert non-image data to images. For example, Ethan Sutin converted sound to images and beat the state of the art on an urban sounds dataset.\n",
    "\n",
    "<img width=500 src=\"sound.png\" alt=\"Pictures of Sounds\"></img>\n",
    "> Credit: https://etown.medium.com/great-results-on-audio-classification-with-fastai-library-ccaf906c5f52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for reading, and congratulations! You now know a lot more about A.I. and deep learning, and it's super important that more people learn about this as it becomes a bigger part of our lives. Be sure to share this knowledge! \n",
    "I will try to keep this updated and make it a great guide. Again, thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
